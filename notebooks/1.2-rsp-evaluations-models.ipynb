{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib as jb\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix, PrecisionRecallCurve, ROCAUC\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             classification_report, \n",
    "                             roc_auc_score, \n",
    "                             accuracy_score,\n",
    "                             precision_recall_curve)\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape X_test_alpha:(114, 30)\n",
      " Shape X_teste_alpha_feature:(114, 9)\n",
      "\n",
      " Shape X_test_beta:(114, 24)\n",
      " Shape X_test_beta_feature(114, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load data X tests to models Group Alpha: \n",
    "X_test_alpha = np.loadtxt('../data/processed/X_data/X_test.csv', delimiter=',') \n",
    "X_test_alpha_feature = np.loadtxt('../data/processed/X_data/X_test_feature.csv', delimiter=',')\n",
    "\n",
    "# Load data X tests to models Group Beta:\n",
    "X_test_beta = np.loadtxt('../data/processed/X_data2/X_test2.csv', delimiter=',') \n",
    "X_test_beta_feature = np.loadtxt('../data/processed/X_data2/X_test2_features.csv', delimiter=',') \n",
    "\n",
    "# Load data target test\n",
    "y_test = np.loadtxt('../data/processed/y_test.csv')\n",
    "\n",
    "print(\n",
    "    f' Shape X_test_alpha:{X_test_alpha.shape}\\n',\n",
    "    f'Shape X_teste_alpha_feature:{X_test_alpha_feature.shape}\\n\\n',\n",
    "    f'Shape X_test_beta:{X_test_beta.shape}\\n',\n",
    "    f'Shape X_test_beta_feature{X_test_beta_feature.shape}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model name: model_alpha_rf_feature\n",
      "Load model name: model_alpha_rf\n",
      "Load model name: model_beta_rf\n",
      "Load model name: model_alpha_svc\n",
      "Load model name: model_beta_xgb\n",
      "Load model name: model_beta_svc\n",
      "Load model name: model_beta_svc_feature\n",
      "Load model name: model_alpha_xgb_feature\n",
      "Load model name: model_beta_rf_feature\n",
      "Load model name: model_alpha_xgb\n",
      "Load model name: model_alpha_svc_feature\n",
      "Load model name: model_beta_xgb_feature\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model_dir = '../models/'\n",
    "models_dict = {}\n",
    "\n",
    "for model_file in os.listdir(model_dir):\n",
    "    if model_file.endswith('.pkl'):\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        model = jb.load(model_path)\n",
    "        model_name = model_file.split('.')[0]\n",
    "        models_dict[model_name] = model\n",
    "        print(f'Load model name: {model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to save AUC results:\n",
    "auc_results ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to summary models results:\n",
    "def summary_classification(model_name:str, X_test):\n",
    "    print(model_name+':')\n",
    "    model = models_dict[model_name]\n",
    "    print(classification_report(y_test, model.predict(X_test)))\n",
    "    print(f'AUC:{round(roc_auc_score(y_test, model.predict(X_test)),3)}')\n",
    "\n",
    "    # save auc value into dict\n",
    "    auc_results[model_name] = [round(roc_auc_score(y_test, model.predict(X_test)),3)]\n",
    "    \n",
    "    # plot confusion matrix as heatmap\n",
    "    conf_mat = confusion_matrix(y_test, model.predict(X_test))\n",
    "    sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.title('Confusion Matrix - Model: '+model_name)\n",
    "    plt.xlabel('Predict')\n",
    "    plt.ylabel('Real')\n",
    "\n",
    "    # save figure\n",
    "    plt.savefig('../reports/figures/models/confusion_matrix_'+model_name+'.png')\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary classification (Precision, recall and F1-score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group model Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_alpha_rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.89      0.94        75\n",
      "         1.0       0.83      0.97      0.89        39\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.93      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "AUC:0.934\n"
     ]
    }
   ],
   "source": [
    "# All feature:\n",
    "summary_classification('model_alpha_rf', X_test_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_alpha_rf_feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.87      0.92        75\n",
      "         1.0       0.79      0.97      0.87        39\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.89      0.92      0.90       114\n",
      "weighted avg       0.92      0.90      0.91       114\n",
      "\n",
      "AUC:0.921\n"
     ]
    }
   ],
   "source": [
    "# Feature seletec: \n",
    "summary_classification('model_alpha_rf_feature', X_test_alpha_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Model Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_beta_rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.91      0.94        75\n",
      "         1.0       0.84      0.97      0.90        39\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.91      0.94      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n",
      "AUC:0.941\n"
     ]
    }
   ],
   "source": [
    "# All feature :\n",
    "summary_classification('model_beta_rf', X_test_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_beta_rf_feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.88      0.93        75\n",
      "         1.0       0.81      0.97      0.88        39\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.93      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "AUC:0.927\n"
     ]
    }
   ],
   "source": [
    "# Feature seleted:\n",
    "summary_classification('model_beta_rf_feature', X_test_beta_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOSTClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group model Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_alpha_xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.91      0.94        75\n",
      "         1.0       0.84      0.97      0.90        39\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.91      0.94      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n",
      "AUC:0.941\n"
     ]
    }
   ],
   "source": [
    "# All feature: \n",
    "summary_classification('model_alpha_xgb', X_test_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_alpha_xgb_feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.88      0.93        75\n",
      "         1.0       0.81      0.97      0.88        39\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.93      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "AUC:0.927\n"
     ]
    }
   ],
   "source": [
    "# Feature selected\n",
    "summary_classification('model_alpha_xgb_feature', X_test_alpha_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Model Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_beta_xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95        75\n",
      "         1.0       0.86      0.97      0.92        39\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.92      0.95      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "AUC:0.947\n"
     ]
    }
   ],
   "source": [
    "# All feature:\n",
    "summary_classification('model_beta_xgb', X_test_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_beta_xgb_feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.87      0.92        75\n",
      "         1.0       0.79      0.97      0.87        39\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.89      0.92      0.90       114\n",
      "weighted avg       0.92      0.90      0.91       114\n",
      "\n",
      "AUC:0.921\n"
     ]
    }
   ],
   "source": [
    "# Feature selected:\n",
    "summary_classification('model_beta_xgb_feature', X_test_beta_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group model Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_alpha_svc:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.95        75\n",
      "         1.0       0.86      0.97      0.92        39\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.92      0.95      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "AUC:0.947\n"
     ]
    }
   ],
   "source": [
    "# All feature:\n",
    "summary_classification('model_alpha_svc', X_test_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_alpha_svc_feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.89      0.94        75\n",
      "         1.0       0.83      0.97      0.89        39\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.91      0.93      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "AUC:0.934\n"
     ]
    }
   ],
   "source": [
    "# Feature selected:\n",
    "summary_classification('model_alpha_svc_feature',X_test_alpha_feature)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group model Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_beta_svc:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.91      0.94        75\n",
      "         1.0       0.84      0.97      0.90        39\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.91      0.94      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n",
      "AUC:0.941\n"
     ]
    }
   ],
   "source": [
    "# All feature: \n",
    "summary_classification('model_beta_svc', X_test_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_beta_svc_feature:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.88      0.93        75\n",
      "         1.0       0.81      0.97      0.88        39\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.93      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "AUC:0.927\n"
     ]
    }
   ],
   "source": [
    "# Feature selected:\n",
    "summary_classification('model_beta_svc_feature', X_test_beta_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_beta_xgb</th>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_alpha_svc</th>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_beta_rf</th>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_alpha_xgb</th>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_beta_svc</th>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_alpha_rf</th>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_alpha_svc_feature</th>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_beta_rf_feature</th>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_alpha_xgb_feature</th>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_beta_svc_feature</th>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_alpha_rf_feature</th>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_beta_xgb_feature</th>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AUC\n",
       "model_beta_xgb           0.947\n",
       "model_alpha_svc          0.947\n",
       "model_beta_rf            0.941\n",
       "model_alpha_xgb          0.941\n",
       "model_beta_svc           0.941\n",
       "model_alpha_rf           0.934\n",
       "model_alpha_svc_feature  0.934\n",
       "model_beta_rf_feature    0.927\n",
       "model_alpha_xgb_feature  0.927\n",
       "model_beta_svc_feature   0.927\n",
       "model_alpha_rf_feature   0.921\n",
       "model_beta_xgb_feature   0.921"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise AUC results:  \n",
    "smr = pd.DataFrame(auc_results).T\n",
    "smr.columns=['AUC']\n",
    "smr.sort_values(by='AUC', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Notes: \n",
    "\n",
    "    - The `model_beta_xgb` and the `model_alpha_svc` show the best AUC scores. To select a model, I'll choose the `model_beta_xgb` because it has fewer features.\n",
    "    \n",
    "    - In this problem, the worst error that the model can make is predicting a cell as benign when it is actually malignant. To reduce this error, I'll focus on improving the recall for malignant cells (class 1 in our case). The current recall rate is 97%, compared to a precision rate of 86%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
